\subsection*{Problem 3.2}

\begin{exercise}[3.2]
Show that there is a protocol for computing greater-than with communication complexity $\lceil \log(1/\epsilon) \rceil$ such that if the inputs are sampled uniformly and independently, then the average case error of the protocol is at most $\epsilon$.
\end{exercise}

\begin{proof}
We suppose that Alice and Bob each have some input $ x, y \in
[k]$. We then can divide this set into $\frac{1}{\epsilon}$ intervals. Alice
Identifyies which interval her input lands in, and communicates this to Bob,
using $\log \frac{1}{\epsilon}$ bits. If Bobs input is in a smaller interval,
the function returns 1, and in all other cases the function returns 0. The
function will have error in the worst case whenever Alice and Bobs inputs are
in the same interval. The communication of the function is $\log
\frac{1}{\epsilon}$, for Alice to tell Bob which interval her input is in, and
the probability that the inputs are in the same interval is
$\frac{1}{\frac{1}{\epsilon}}$, or $\epsilon$.
\end{proof}
